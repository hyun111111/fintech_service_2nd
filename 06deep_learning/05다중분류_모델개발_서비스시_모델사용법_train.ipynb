{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e241047",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d68c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26dc4930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>와인_종류</th>\n",
       "      <th>알코올_도수</th>\n",
       "      <th>사과산_함량</th>\n",
       "      <th>재_함량</th>\n",
       "      <th>재의_알칼리도</th>\n",
       "      <th>마그네슘_함량</th>\n",
       "      <th>총_페놀_함량</th>\n",
       "      <th>플라보노이드_함량</th>\n",
       "      <th>비플라보노이드_페놀_함량</th>\n",
       "      <th>프로안토시아닌_함량</th>\n",
       "      <th>색_강도</th>\n",
       "      <th>색조</th>\n",
       "      <th>희석_와인의_투과율_OD280_OD315</th>\n",
       "      <th>프롤린_함량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.76</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.70</td>\n",
       "      <td>19.5</td>\n",
       "      <td>132</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.35</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12.67</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.24</td>\n",
       "      <td>18.0</td>\n",
       "      <td>99</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.46</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.16</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.58</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.36</td>\n",
       "      <td>19.1</td>\n",
       "      <td>106</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.95</td>\n",
       "      <td>6.90</td>\n",
       "      <td>1.09</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>13.86</td>\n",
       "      <td>1.51</td>\n",
       "      <td>2.67</td>\n",
       "      <td>25.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.38</td>\n",
       "      <td>1.36</td>\n",
       "      <td>3.16</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.22</td>\n",
       "      <td>25.0</td>\n",
       "      <td>124</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3.20</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "      <td>12.43</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.29</td>\n",
       "      <td>21.5</td>\n",
       "      <td>86</td>\n",
       "      <td>2.74</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.84</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3</td>\n",
       "      <td>12.20</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.32</td>\n",
       "      <td>19.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.73</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.83</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>13.51</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>19.0</td>\n",
       "      <td>110</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.54</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>12.70</td>\n",
       "      <td>3.87</td>\n",
       "      <td>2.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.19</td>\n",
       "      <td>3.13</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2</td>\n",
       "      <td>12.51</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.98</td>\n",
       "      <td>20.5</td>\n",
       "      <td>85</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.57</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     와인_종류  알코올_도수  사과산_함량  재_함량  재의_알칼리도  마그네슘_함량  총_페놀_함량  플라보노이드_함량  \\\n",
       "0        1   13.76    1.53  2.70     19.5      132     2.95       2.74   \n",
       "1        2   12.67    0.98  2.24     18.0       99     2.20       1.94   \n",
       "2        1   13.58    1.66  2.36     19.1      106     2.86       3.19   \n",
       "3        2   13.86    1.51  2.67     25.0       86     2.95       2.86   \n",
       "4        1   13.05    2.05  3.22     25.0      124     2.63       2.68   \n",
       "..     ...     ...     ...   ...      ...      ...      ...        ...   \n",
       "101      2   12.43    1.53  2.29     21.5       86     2.74       3.15   \n",
       "102      3   12.20    3.03  2.32     19.0       96     1.25       0.49   \n",
       "103      1   13.51    1.80  2.65     19.0      110     2.35       2.53   \n",
       "104      2   12.70    3.87  2.40     23.0      101     2.83       2.55   \n",
       "105      2   12.51    1.73  1.98     20.5       85     2.20       1.92   \n",
       "\n",
       "     비플라보노이드_페놀_함량  프로안토시아닌_함량  색_강도    색조  희석_와인의_투과율_OD280_OD315  프롤린_함량  \n",
       "0             0.50        1.35  5.40  1.25                    3.00    1235  \n",
       "1             0.30        1.46  2.62  1.23                    3.16     450  \n",
       "2             0.22        1.95  6.90  1.09                    2.88    1515  \n",
       "3             0.21        1.87  3.38  1.36                    3.16     410  \n",
       "4             0.47        1.92  3.58  1.13                    3.20     830  \n",
       "..             ...         ...   ...   ...                     ...     ...  \n",
       "101           0.39        1.77  3.94  0.69                    2.84     352  \n",
       "102           0.40        0.73  5.50  0.66                    1.83     510  \n",
       "103           0.29        1.54  4.20  1.10                    2.87    1095  \n",
       "104           0.43        1.95  2.57  1.19                    3.13     463  \n",
       "105           0.32        1.48  2.94  1.04                    3.57     672  \n",
       "\n",
       "[106 rows x 14 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/wine_train.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58aa31af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "와인_종류\n",
       "2    42\n",
       "1    35\n",
       "3    29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['와인_종류'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dea779c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 106 entries, 0 to 105\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   와인_종류                   106 non-null    int64  \n",
      " 1   알코올_도수                  106 non-null    float64\n",
      " 2   사과산_함량                  106 non-null    float64\n",
      " 3   재_함량                    106 non-null    float64\n",
      " 4   재의_알칼리도                 106 non-null    float64\n",
      " 5   마그네슘_함량                 106 non-null    int64  \n",
      " 6   총_페놀_함량                 106 non-null    float64\n",
      " 7   플라보노이드_함량               106 non-null    float64\n",
      " 8   비플라보노이드_페놀_함량           106 non-null    float64\n",
      " 9   프로안토시아닌_함량              106 non-null    float64\n",
      " 10  색_강도                    106 non-null    float64\n",
      " 11  색조                      106 non-null    float64\n",
      " 12  희석_와인의_투과율_OD280_OD315  106 non-null    float64\n",
      " 13  프롤린_함량                  106 non-null    int64  \n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 11.7 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18bcf0b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data.iloc[:,6:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e39d7fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7db265ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('와인_종류', axis=1)\n",
    "y = data['와인_종류']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "798b34d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X ,y, test_size=0.4, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c14eae8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m ss \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m      2\u001b[0m train_temp \u001b[38;5;241m=\u001b[39m ss\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[0;32m----> 3\u001b[0m test_temp \u001b[38;5;241m=\u001b[39m ss\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_valid\u001b[49m)\n\u001b[1;32m      4\u001b[0m ss_X_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(train_temp, columns\u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mcolumns, index\u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m      5\u001b[0m ss_X_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(valid_temp, columns\u001b[38;5;241m=\u001b[39m X_valid\u001b[38;5;241m.\u001b[39mcolumns, index\u001b[38;5;241m=\u001b[39m X_valid\u001b[38;5;241m.\u001b[39mindex)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_valid' is not defined"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "train_temp = ss.fit_transform(X_train)\n",
    "test_temp = ss.fit_transform(X_valid)\n",
    "ss_X_train = pd.DataFrame(train_temp, columns= X_train.columns, index= X_train.index)\n",
    "ss_X_test = pd.DataFrame(valid_temp, columns= X_valid.columns, index= X_valid.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29747b25",
   "metadata": {},
   "source": [
    "스케일러 민 맥스로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3c884ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "train_temp = mms.fit_transform(X_train)\n",
    "test_temp = mms.transform(X_test)\n",
    "mms_X_train = pd.DataFrame(train_temp, columns= X_train.columns, index= X_train.index)\n",
    "mms_X_test = pd.DataFrame(test_temp, columns= X_test.columns, index= X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e862d",
   "metadata": {},
   "source": [
    "# mms 변수에 있는 MinMaxScaler 가중치 저장\n",
    "# joblib\n",
    "* joblib.dump(경로, 파일명)\n",
    "* joblib.load(경로, 파일명) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab3b3277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68263d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/MinMax_info.joblib']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mms, \"./model/MinMax_info.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f655d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43770464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0cb9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b32ff607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>알코올_도수</th>\n",
       "      <th>사과산_함량</th>\n",
       "      <th>재_함량</th>\n",
       "      <th>재의_알칼리도</th>\n",
       "      <th>마그네슘_함량</th>\n",
       "      <th>총_페놀_함량</th>\n",
       "      <th>플라보노이드_함량</th>\n",
       "      <th>비플라보노이드_페놀_함량</th>\n",
       "      <th>프로안토시아닌_함량</th>\n",
       "      <th>색_강도</th>\n",
       "      <th>색조</th>\n",
       "      <th>희석_와인의_투과율_OD280_OD315</th>\n",
       "      <th>프롤린_함량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.476316</td>\n",
       "      <td>0.418033</td>\n",
       "      <td>0.672043</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>0.411538</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.310580</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.316602</td>\n",
       "      <td>0.252223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.207895</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.542683</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.349650</td>\n",
       "      <td>0.066553</td>\n",
       "      <td>0.373984</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.110752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.153689</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.725610</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.190625</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.893345</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.173745</td>\n",
       "      <td>0.276475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.507895</td>\n",
       "      <td>0.518443</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>0.481707</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.053846</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.341297</td>\n",
       "      <td>0.162602</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.320938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.182377</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.513652</td>\n",
       "      <td>0.650407</td>\n",
       "      <td>0.598456</td>\n",
       "      <td>0.834276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.610656</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.664634</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.251748</td>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.423684</td>\n",
       "      <td>0.090164</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.296154</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.381399</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.100386</td>\n",
       "      <td>0.139046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.621053</td>\n",
       "      <td>0.174180</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.335366</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.360140</td>\n",
       "      <td>0.300341</td>\n",
       "      <td>0.357724</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.741310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.435484</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.778125</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.334471</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.586873</td>\n",
       "      <td>0.620049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.307895</td>\n",
       "      <td>0.432377</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.108392</td>\n",
       "      <td>0.360068</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.193050</td>\n",
       "      <td>0.187551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       알코올_도수    사과산_함량      재_함량   재의_알칼리도   마그네슘_함량   총_페놀_함량  플라보노이드_함량  \\\n",
       "77   0.476316  0.418033  0.672043  0.817073  0.217949  0.411538   0.034375   \n",
       "20   0.207895  0.163934  0.279570  0.542683  0.025641  0.480769   0.359375   \n",
       "24   0.644737  0.153689  0.688172  0.725610  0.064103  0.519231   0.190625   \n",
       "85   0.507895  0.518443  0.532258  0.481707  0.282051  0.053846   0.065625   \n",
       "32   0.684211  0.182377  0.720430  0.402439  0.358974  0.615385   0.756250   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "49   0.539474  0.610656  0.537634  0.664634  0.371795  0.061538   0.281250   \n",
       "80   0.423684  0.090164  0.354839  0.378049  0.205128  0.296154   0.287500   \n",
       "33   0.621053  0.174180  0.677419  0.335366  0.115385  0.615385   0.765625   \n",
       "9    1.000000  0.147541  0.435484  0.207317  0.166667  0.596154   0.778125   \n",
       "102  0.307895  0.432377  0.516129  0.512195  0.153846  0.000000   0.000000   \n",
       "\n",
       "     비플라보노이드_페놀_함량  프로안토시아닌_함량      색_강도        색조  희석_와인의_투과율_OD280_OD315  \\\n",
       "77        0.795918    0.136364  0.310580  0.333333                0.316602   \n",
       "20        0.469388    0.349650  0.066553  0.373984                0.428571   \n",
       "24        0.775510    0.653846  0.893345  0.073171                0.173745   \n",
       "85        0.530612    0.181818  0.341297  0.162602                0.162162   \n",
       "32        0.326531    0.363636  0.513652  0.650407                0.598456   \n",
       "..             ...         ...       ...       ...                     ...   \n",
       "49        0.408163    0.251748  0.692833  0.073171                0.000000   \n",
       "80        0.795918    0.069930  0.381399  0.406504                0.100386   \n",
       "33        0.408163    0.360140  0.300341  0.357724                0.729730   \n",
       "9         0.306122    0.545455  0.334471  0.487805                0.586873   \n",
       "102       0.530612    0.108392  0.360068  0.146341                0.193050   \n",
       "\n",
       "       프롤린_함량  \n",
       "77   0.252223  \n",
       "20   0.110752  \n",
       "24   0.276475  \n",
       "85   0.320938  \n",
       "32   0.834276  \n",
       "..        ...  \n",
       "49   0.219887  \n",
       "80   0.139046  \n",
       "33   0.741310  \n",
       "9    0.620049  \n",
       "102  0.187551  \n",
       "\n",
       "[63 rows x 13 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mms_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3f7e745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>알코올_도수</th>\n",
       "      <th>사과산_함량</th>\n",
       "      <th>재_함량</th>\n",
       "      <th>재의_알칼리도</th>\n",
       "      <th>마그네슘_함량</th>\n",
       "      <th>총_페놀_함량</th>\n",
       "      <th>플라보노이드_함량</th>\n",
       "      <th>비플라보노이드_페놀_함량</th>\n",
       "      <th>프로안토시아닌_함량</th>\n",
       "      <th>색_강도</th>\n",
       "      <th>색조</th>\n",
       "      <th>희석_와인의_투과율_OD280_OD315</th>\n",
       "      <th>프롤린_함량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.331579</td>\n",
       "      <td>0.461066</td>\n",
       "      <td>0.456989</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.087031</td>\n",
       "      <td>0.764228</td>\n",
       "      <td>0.579151</td>\n",
       "      <td>0.103476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.254098</td>\n",
       "      <td>0.435484</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.325175</td>\n",
       "      <td>0.126280</td>\n",
       "      <td>0.308943</td>\n",
       "      <td>0.752896</td>\n",
       "      <td>0.080841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.834211</td>\n",
       "      <td>0.172131</td>\n",
       "      <td>0.586022</td>\n",
       "      <td>0.280488</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.541958</td>\n",
       "      <td>0.466724</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.586873</td>\n",
       "      <td>0.947454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.487705</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.481707</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.506993</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.065041</td>\n",
       "      <td>0.069498</td>\n",
       "      <td>0.320938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.450820</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.290210</td>\n",
       "      <td>0.624573</td>\n",
       "      <td>0.089431</td>\n",
       "      <td>-0.011583</td>\n",
       "      <td>0.179466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.839474</td>\n",
       "      <td>0.159836</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.347561</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.562937</td>\n",
       "      <td>0.435154</td>\n",
       "      <td>0.373984</td>\n",
       "      <td>0.764479</td>\n",
       "      <td>0.559418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.096311</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.725610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.216783</td>\n",
       "      <td>0.138225</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.718147</td>\n",
       "      <td>0.086500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.113158</td>\n",
       "      <td>0.577869</td>\n",
       "      <td>0.247312</td>\n",
       "      <td>0.542683</td>\n",
       "      <td>0.294872</td>\n",
       "      <td>0.742308</td>\n",
       "      <td>0.653125</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>1.104895</td>\n",
       "      <td>0.138225</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.229588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.352632</td>\n",
       "      <td>0.059426</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.457317</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.580420</td>\n",
       "      <td>0.283276</td>\n",
       "      <td>0.577236</td>\n",
       "      <td>0.374517</td>\n",
       "      <td>0.323363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.244737</td>\n",
       "      <td>0.034836</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>-0.020408</td>\n",
       "      <td>0.430070</td>\n",
       "      <td>0.164676</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.694981</td>\n",
       "      <td>0.491512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.365789</td>\n",
       "      <td>0.141393</td>\n",
       "      <td>0.446237</td>\n",
       "      <td>0.725610</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.416084</td>\n",
       "      <td>0.066553</td>\n",
       "      <td>0.471545</td>\n",
       "      <td>0.629344</td>\n",
       "      <td>0.054163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.665789</td>\n",
       "      <td>0.165984</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.603659</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.657692</td>\n",
       "      <td>0.715625</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.424061</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.656371</td>\n",
       "      <td>0.680679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.352632</td>\n",
       "      <td>0.051230</td>\n",
       "      <td>0.301075</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.471875</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.216783</td>\n",
       "      <td>0.290102</td>\n",
       "      <td>0.520325</td>\n",
       "      <td>0.830116</td>\n",
       "      <td>0.187551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.331579</td>\n",
       "      <td>0.141393</td>\n",
       "      <td>0.456989</td>\n",
       "      <td>0.597561</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>-0.057692</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.151024</td>\n",
       "      <td>0.346341</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.478577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.321053</td>\n",
       "      <td>0.165984</td>\n",
       "      <td>0.408602</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>-0.051282</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.481250</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.180887</td>\n",
       "      <td>0.422764</td>\n",
       "      <td>0.710425</td>\n",
       "      <td>0.187551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>0.467742</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>-0.051282</td>\n",
       "      <td>-0.103846</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.308874</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.664634</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.472028</td>\n",
       "      <td>0.226962</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.583012</td>\n",
       "      <td>0.059822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.186475</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.541958</td>\n",
       "      <td>0.218430</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.575586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.765789</td>\n",
       "      <td>0.165984</td>\n",
       "      <td>0.489247</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.626923</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.580420</td>\n",
       "      <td>0.650171</td>\n",
       "      <td>0.520325</td>\n",
       "      <td>0.683398</td>\n",
       "      <td>0.793856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.744737</td>\n",
       "      <td>0.120902</td>\n",
       "      <td>0.704301</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.740625</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.506993</td>\n",
       "      <td>0.179181</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.706564</td>\n",
       "      <td>0.106710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.823684</td>\n",
       "      <td>0.325820</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.165385</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.286713</td>\n",
       "      <td>0.718430</td>\n",
       "      <td>0.113821</td>\n",
       "      <td>0.146718</td>\n",
       "      <td>0.308812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.531579</td>\n",
       "      <td>0.174180</td>\n",
       "      <td>0.397849</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.294872</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.562937</td>\n",
       "      <td>0.320819</td>\n",
       "      <td>0.325203</td>\n",
       "      <td>0.779923</td>\n",
       "      <td>0.490703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.439474</td>\n",
       "      <td>0.538934</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.664634</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.146853</td>\n",
       "      <td>0.317406</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>-0.015444</td>\n",
       "      <td>0.260307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.194672</td>\n",
       "      <td>0.586022</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.634375</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.338737</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.868726</td>\n",
       "      <td>0.818108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.623684</td>\n",
       "      <td>0.612705</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.513652</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.088803</td>\n",
       "      <td>0.381568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.626316</td>\n",
       "      <td>0.598361</td>\n",
       "      <td>0.408602</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.684375</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.255973</td>\n",
       "      <td>0.349593</td>\n",
       "      <td>0.644788</td>\n",
       "      <td>0.611964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.606250</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.402098</td>\n",
       "      <td>0.317406</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.575290</td>\n",
       "      <td>0.810024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.298780</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.684375</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.328671</td>\n",
       "      <td>0.283276</td>\n",
       "      <td>0.495935</td>\n",
       "      <td>0.559846</td>\n",
       "      <td>0.486661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.594737</td>\n",
       "      <td>0.215164</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.433566</td>\n",
       "      <td>0.402730</td>\n",
       "      <td>0.479675</td>\n",
       "      <td>0.583012</td>\n",
       "      <td>0.801940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.613158</td>\n",
       "      <td>0.336066</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.368601</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.440154</td>\n",
       "      <td>0.405821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.387295</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.111538</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.283276</td>\n",
       "      <td>0.235772</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.260307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.471053</td>\n",
       "      <td>0.502049</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.542683</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.088462</td>\n",
       "      <td>0.053125</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.766212</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.329022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.043033</td>\n",
       "      <td>0.618280</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.340625</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.342657</td>\n",
       "      <td>0.078498</td>\n",
       "      <td>0.674797</td>\n",
       "      <td>0.536680</td>\n",
       "      <td>0.284559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.118852</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.725610</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.685315</td>\n",
       "      <td>0.377133</td>\n",
       "      <td>0.577236</td>\n",
       "      <td>0.532819</td>\n",
       "      <td>0.814066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.484211</td>\n",
       "      <td>0.756148</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.664634</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.543515</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.204633</td>\n",
       "      <td>0.280517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.310526</td>\n",
       "      <td>0.055328</td>\n",
       "      <td>0.209677</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.246875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.133959</td>\n",
       "      <td>0.650407</td>\n",
       "      <td>0.671815</td>\n",
       "      <td>0.355699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.547368</td>\n",
       "      <td>0.200820</td>\n",
       "      <td>0.747312</td>\n",
       "      <td>0.908537</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.246875</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.398601</td>\n",
       "      <td>0.496587</td>\n",
       "      <td>0.105691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.652632</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.391608</td>\n",
       "      <td>0.249147</td>\n",
       "      <td>0.504065</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.660469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.186475</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.481707</td>\n",
       "      <td>-0.038462</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.315625</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.426573</td>\n",
       "      <td>0.095563</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.362934</td>\n",
       "      <td>0.163298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.531579</td>\n",
       "      <td>0.602459</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.725610</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.419580</td>\n",
       "      <td>0.300341</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.262548</td>\n",
       "      <td>0.191593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.424180</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.228125</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.143357</td>\n",
       "      <td>0.351536</td>\n",
       "      <td>0.211382</td>\n",
       "      <td>0.034749</td>\n",
       "      <td>0.203719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.036885</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.473077</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.356643</td>\n",
       "      <td>0.153584</td>\n",
       "      <td>0.504065</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.126112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.721053</td>\n",
       "      <td>0.200820</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.396341</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.440559</td>\n",
       "      <td>0.428328</td>\n",
       "      <td>0.528455</td>\n",
       "      <td>0.617761</td>\n",
       "      <td>0.886823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       알코올_도수    사과산_함량      재_함량   재의_알칼리도   마그네슘_함량   총_페놀_함량  플라보노이드_함량  \\\n",
       "40   0.331579  0.461066  0.456989  0.451220  0.051282  0.615385   0.781250   \n",
       "96   0.273684  0.254098  0.435484  0.634146  0.012821  0.519231   0.675000   \n",
       "82   0.834211  0.172131  0.586022  0.280488  0.358974  0.776923   0.906250   \n",
       "71   0.578947  0.487705  0.494624  0.481707  0.179487  0.211538   0.106250   \n",
       "78   0.650000  0.450820  0.677419  0.817073  0.500000  0.057692   0.337500   \n",
       "90   0.839474  0.159836  0.505376  0.347561  0.435897  0.750000   0.784375   \n",
       "68   0.276316  0.096311  0.612903  0.725610  0.000000  0.503846   0.562500   \n",
       "19   0.113158  0.577869  0.247312  0.542683  0.294872  0.742308   0.653125   \n",
       "42   0.352632  0.059426  0.645161  0.457317  0.179487  0.450000   0.675000   \n",
       "35   0.244737  0.034836  0.505376  0.634146  0.217949  0.819231   0.515625   \n",
       "66   0.365789  0.141393  0.446237  0.725610  0.307692  0.288462   0.500000   \n",
       "93   0.665789  0.165984  0.591398  0.603659  0.410256  0.657692   0.715625   \n",
       "34   0.352632  0.051230  0.301075  0.548780 -0.076923  0.330769   0.471875   \n",
       "63   0.331579  0.141393  0.456989  0.597561  0.243590 -0.057692   0.165625   \n",
       "8    0.321053  0.165984  0.408602  0.512195 -0.051282  0.153846   0.481250   \n",
       "97   0.750000  0.844262  0.467742  0.573171 -0.051282 -0.103846  -0.046875   \n",
       "101  0.368421  0.125000  0.500000  0.664634  0.025641  0.573077   0.831250   \n",
       "14   0.697368  0.186475  0.537634  0.402439  0.256410  0.450000   0.687500   \n",
       "55   0.765789  0.165984  0.489247  0.414634  0.307692  0.626923   0.953125   \n",
       "3    0.744737  0.120902  0.704301  0.878049  0.025641  0.653846   0.740625   \n",
       "92   0.823684  0.325820  0.602151  0.573171  0.089744  0.165385   0.065625   \n",
       "30   0.531579  0.174180  0.397849  0.390244  0.294872  0.673077   0.784375   \n",
       "81   0.439474  0.538934  0.537634  0.664634  0.282051  0.173077   0.221875   \n",
       "64   0.884211  0.194672  0.586022  0.243902  0.153846  0.480769   0.634375   \n",
       "15   0.623684  0.612705  0.602151  0.756098  0.230769  0.211538   0.081250   \n",
       "52   0.626316  0.598361  0.408602  0.500000  0.076923  0.461538   0.684375   \n",
       "58   0.813158  0.114754  0.516129  0.378049  0.141026  0.365385   0.606250   \n",
       "11   0.592105  0.147541  0.795699  0.298780  0.333333  0.519231   0.684375   \n",
       "38   0.594737  0.215164  0.709677  0.378049  0.230769  0.673077   0.856250   \n",
       "65   0.613158  0.336066  0.532258  0.573171  0.064103  0.057692   0.003125   \n",
       "87   0.500000  0.387295  0.720430  0.634146  0.153846  0.111538   0.003125   \n",
       "31   0.471053  0.502049  0.505376  0.542683  0.051282  0.088462   0.053125   \n",
       "21   0.276316  0.043033  0.618280  0.817073 -0.076923  0.288462   0.340625   \n",
       "5    0.710526  0.118852  0.720430  0.725610  0.217949  0.673077   0.862500   \n",
       "59   0.484211  0.756148  0.602151  0.664634  0.025641  0.173077   0.050000   \n",
       "12   0.310526  0.055328  0.209677  0.378049  0.858974  0.230769   0.246875   \n",
       "69   0.547368  0.200820  0.747312  0.908537  0.410256  0.365385   0.246875   \n",
       "103  0.652632  0.180328  0.693548  0.512195  0.333333  0.423077   0.637500   \n",
       "95   0.276316  0.186475  0.516129  0.481707 -0.038462  0.134615   0.315625   \n",
       "100  0.531579  0.602459  0.516129  0.725610  0.012821  0.153846   0.343750   \n",
       "61   0.486842  0.424180  0.559140  0.573171  0.256410  0.019231   0.228125   \n",
       "44   0.100000 -0.036885  0.612903  0.634146  0.051282  0.473077   0.475000   \n",
       "57   0.721053  0.200820  0.709677  0.396341  0.397436  0.673077   0.718750   \n",
       "\n",
       "     비플라보노이드_페놀_함량  프로안토시아닌_함량      색_강도        색조  희석_와인의_투과율_OD280_OD315  \\\n",
       "40        0.632653    0.835664  0.087031  0.764228                0.579151   \n",
       "96        0.469388    0.325175  0.126280  0.308943                0.752896   \n",
       "82        0.408163    0.541958  0.466724  0.463415                0.586873   \n",
       "71        0.959184    0.506993  0.788396  0.065041                0.069498   \n",
       "78        0.163265    0.290210  0.624573  0.089431               -0.011583   \n",
       "90        0.244898    0.562937  0.435154  0.373984                0.764479   \n",
       "68        0.591837    0.216783  0.138225  0.365854                0.718147   \n",
       "19        0.204082    1.104895  0.138225  0.219512                0.571429   \n",
       "42        0.469388    0.580420  0.283276  0.577236                0.374517   \n",
       "35       -0.020408    0.430070  0.164676  0.414634                0.694981   \n",
       "66        0.408163    0.416084  0.066553  0.471545                0.629344   \n",
       "93        0.122449    0.709790  0.424061  0.406504                0.656371   \n",
       "34        0.265306    0.216783  0.290102  0.520325                0.830116   \n",
       "63        0.469388    0.363636  0.151024  0.346341                0.189189   \n",
       "8         0.469388    0.423077  0.180887  0.422764                0.710425   \n",
       "97        0.530612    0.090909  0.308874  0.081301                0.000000   \n",
       "101       0.510204    0.472028  0.226962  0.170732                0.583012   \n",
       "14        0.571429    0.541958  0.218430  0.609756                0.594595   \n",
       "55        0.367347    0.580420  0.650171  0.520325                0.683398   \n",
       "3         0.142857    0.506993  0.179181  0.715447                0.706564   \n",
       "92        0.612245    0.286713  0.718430  0.113821                0.146718   \n",
       "30        0.285714    0.562937  0.320819  0.325203                0.779923   \n",
       "81        0.061224    0.146853  0.317406  0.243902               -0.015444   \n",
       "64        0.326531    0.545455  0.338737  0.439024                0.868726   \n",
       "15        0.591837    0.346154  0.513652  0.178862                0.088803   \n",
       "52        0.265306    0.370629  0.255973  0.349593                0.644788   \n",
       "58        0.244898    0.402098  0.317406  0.560976                0.575290   \n",
       "11        0.408163    0.328671  0.283276  0.495935                0.559846   \n",
       "38        0.346939    0.433566  0.402730  0.479675                0.583012   \n",
       "65        0.469388    0.076923  0.368601  0.178862                0.440154   \n",
       "87        0.795918    0.115385  0.283276  0.235772                0.378378   \n",
       "31        0.530612    0.192308  0.766212  0.195122                0.162162   \n",
       "21        0.530612    0.342657  0.078498  0.674797                0.536680   \n",
       "5         0.306122    0.685315  0.377133  0.577236                0.532819   \n",
       "59        0.673469    0.153846  0.543515  0.048780                0.204633   \n",
       "12        0.000000    0.727273  0.133959  0.650407                0.671815   \n",
       "69        0.244898    0.398601  0.496587  0.105691                0.000000   \n",
       "103       0.306122    0.391608  0.249147  0.504065                0.594595   \n",
       "95        0.775510    0.426573  0.095563  0.487805                0.362934   \n",
       "100       0.959184    0.419580  0.300341  0.292683                0.262548   \n",
       "61        0.204082    0.143357  0.351536  0.211382                0.034749   \n",
       "44        0.571429    0.356643  0.153584  0.504065                0.378378   \n",
       "57        0.510204    0.440559  0.428328  0.528455                0.617761   \n",
       "\n",
       "       프롤린_함량  \n",
       "40   0.103476  \n",
       "96   0.080841  \n",
       "82   0.947454  \n",
       "71   0.320938  \n",
       "78   0.179466  \n",
       "90   0.559418  \n",
       "68   0.086500  \n",
       "19   0.229588  \n",
       "42   0.323363  \n",
       "35   0.491512  \n",
       "66   0.054163  \n",
       "93   0.680679  \n",
       "34   0.187551  \n",
       "63   0.478577  \n",
       "8    0.187551  \n",
       "97   0.110752  \n",
       "101  0.059822  \n",
       "14   0.575586  \n",
       "55   0.793856  \n",
       "3    0.106710  \n",
       "92   0.308812  \n",
       "30   0.490703  \n",
       "81   0.260307  \n",
       "64   0.818108  \n",
       "15   0.381568  \n",
       "52   0.611964  \n",
       "58   0.810024  \n",
       "11   0.486661  \n",
       "38   0.801940  \n",
       "65   0.405821  \n",
       "87   0.260307  \n",
       "31   0.329022  \n",
       "21   0.284559  \n",
       "5    0.814066  \n",
       "59   0.280517  \n",
       "12   0.355699  \n",
       "69   0.118836  \n",
       "103  0.660469  \n",
       "95   0.163298  \n",
       "100  0.191593  \n",
       "61   0.203719  \n",
       "44   0.126112  \n",
       "57   0.886823  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mms_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "835386d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "와인_종류\n",
       "2    25\n",
       "1    21\n",
       "3    17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754308eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0059a8e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ba978b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abcd2a",
   "metadata": {},
   "source": [
    "y 원핫인코딩 배먹음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "321cd15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe9918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b86e1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>알코올_도수</th>\n",
       "      <th>사과산_함량</th>\n",
       "      <th>재_함량</th>\n",
       "      <th>재의_알칼리도</th>\n",
       "      <th>마그네슘_함량</th>\n",
       "      <th>총_페놀_함량</th>\n",
       "      <th>플라보노이드_함량</th>\n",
       "      <th>비플라보노이드_페놀_함량</th>\n",
       "      <th>프로안토시아닌_함량</th>\n",
       "      <th>색_강도</th>\n",
       "      <th>색조</th>\n",
       "      <th>희석_와인의_투과율_OD280_OD315</th>\n",
       "      <th>프롤린_함량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.331579</td>\n",
       "      <td>0.461066</td>\n",
       "      <td>0.456989</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.087031</td>\n",
       "      <td>0.764228</td>\n",
       "      <td>0.579151</td>\n",
       "      <td>0.103476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.254098</td>\n",
       "      <td>0.435484</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.325175</td>\n",
       "      <td>0.126280</td>\n",
       "      <td>0.308943</td>\n",
       "      <td>0.752896</td>\n",
       "      <td>0.080841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.834211</td>\n",
       "      <td>0.172131</td>\n",
       "      <td>0.586022</td>\n",
       "      <td>0.280488</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.541958</td>\n",
       "      <td>0.466724</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.586873</td>\n",
       "      <td>0.947454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.487705</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.481707</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.506993</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.065041</td>\n",
       "      <td>0.069498</td>\n",
       "      <td>0.320938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.450820</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.290210</td>\n",
       "      <td>0.624573</td>\n",
       "      <td>0.089431</td>\n",
       "      <td>-0.011583</td>\n",
       "      <td>0.179466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.839474</td>\n",
       "      <td>0.159836</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.347561</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.562937</td>\n",
       "      <td>0.435154</td>\n",
       "      <td>0.373984</td>\n",
       "      <td>0.764479</td>\n",
       "      <td>0.559418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.096311</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.725610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.216783</td>\n",
       "      <td>0.138225</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.718147</td>\n",
       "      <td>0.086500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.113158</td>\n",
       "      <td>0.577869</td>\n",
       "      <td>0.247312</td>\n",
       "      <td>0.542683</td>\n",
       "      <td>0.294872</td>\n",
       "      <td>0.742308</td>\n",
       "      <td>0.653125</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>1.104895</td>\n",
       "      <td>0.138225</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.229588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.352632</td>\n",
       "      <td>0.059426</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.457317</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.580420</td>\n",
       "      <td>0.283276</td>\n",
       "      <td>0.577236</td>\n",
       "      <td>0.374517</td>\n",
       "      <td>0.323363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.244737</td>\n",
       "      <td>0.034836</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>-0.020408</td>\n",
       "      <td>0.430070</td>\n",
       "      <td>0.164676</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.694981</td>\n",
       "      <td>0.491512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.365789</td>\n",
       "      <td>0.141393</td>\n",
       "      <td>0.446237</td>\n",
       "      <td>0.725610</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.416084</td>\n",
       "      <td>0.066553</td>\n",
       "      <td>0.471545</td>\n",
       "      <td>0.629344</td>\n",
       "      <td>0.054163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.665789</td>\n",
       "      <td>0.165984</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.603659</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.657692</td>\n",
       "      <td>0.715625</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.424061</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.656371</td>\n",
       "      <td>0.680679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.352632</td>\n",
       "      <td>0.051230</td>\n",
       "      <td>0.301075</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.471875</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.216783</td>\n",
       "      <td>0.290102</td>\n",
       "      <td>0.520325</td>\n",
       "      <td>0.830116</td>\n",
       "      <td>0.187551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.331579</td>\n",
       "      <td>0.141393</td>\n",
       "      <td>0.456989</td>\n",
       "      <td>0.597561</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>-0.057692</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.151024</td>\n",
       "      <td>0.346341</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.478577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.321053</td>\n",
       "      <td>0.165984</td>\n",
       "      <td>0.408602</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>-0.051282</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.481250</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.180887</td>\n",
       "      <td>0.422764</td>\n",
       "      <td>0.710425</td>\n",
       "      <td>0.187551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>0.467742</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>-0.051282</td>\n",
       "      <td>-0.103846</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.308874</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.664634</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.472028</td>\n",
       "      <td>0.226962</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.583012</td>\n",
       "      <td>0.059822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.186475</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.541958</td>\n",
       "      <td>0.218430</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.575586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.765789</td>\n",
       "      <td>0.165984</td>\n",
       "      <td>0.489247</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.626923</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.580420</td>\n",
       "      <td>0.650171</td>\n",
       "      <td>0.520325</td>\n",
       "      <td>0.683398</td>\n",
       "      <td>0.793856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.744737</td>\n",
       "      <td>0.120902</td>\n",
       "      <td>0.704301</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.740625</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.506993</td>\n",
       "      <td>0.179181</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.706564</td>\n",
       "      <td>0.106710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.823684</td>\n",
       "      <td>0.325820</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.165385</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.286713</td>\n",
       "      <td>0.718430</td>\n",
       "      <td>0.113821</td>\n",
       "      <td>0.146718</td>\n",
       "      <td>0.308812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.531579</td>\n",
       "      <td>0.174180</td>\n",
       "      <td>0.397849</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.294872</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.562937</td>\n",
       "      <td>0.320819</td>\n",
       "      <td>0.325203</td>\n",
       "      <td>0.779923</td>\n",
       "      <td>0.490703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.439474</td>\n",
       "      <td>0.538934</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.664634</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.146853</td>\n",
       "      <td>0.317406</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>-0.015444</td>\n",
       "      <td>0.260307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.194672</td>\n",
       "      <td>0.586022</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.634375</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.338737</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.868726</td>\n",
       "      <td>0.818108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.623684</td>\n",
       "      <td>0.612705</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.513652</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.088803</td>\n",
       "      <td>0.381568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.626316</td>\n",
       "      <td>0.598361</td>\n",
       "      <td>0.408602</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.684375</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.255973</td>\n",
       "      <td>0.349593</td>\n",
       "      <td>0.644788</td>\n",
       "      <td>0.611964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.606250</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.402098</td>\n",
       "      <td>0.317406</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.575290</td>\n",
       "      <td>0.810024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.298780</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.684375</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.328671</td>\n",
       "      <td>0.283276</td>\n",
       "      <td>0.495935</td>\n",
       "      <td>0.559846</td>\n",
       "      <td>0.486661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.594737</td>\n",
       "      <td>0.215164</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.433566</td>\n",
       "      <td>0.402730</td>\n",
       "      <td>0.479675</td>\n",
       "      <td>0.583012</td>\n",
       "      <td>0.801940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.613158</td>\n",
       "      <td>0.336066</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.368601</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.440154</td>\n",
       "      <td>0.405821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.387295</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.111538</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.283276</td>\n",
       "      <td>0.235772</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.260307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.471053</td>\n",
       "      <td>0.502049</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.542683</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.088462</td>\n",
       "      <td>0.053125</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.766212</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.329022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.043033</td>\n",
       "      <td>0.618280</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.340625</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.342657</td>\n",
       "      <td>0.078498</td>\n",
       "      <td>0.674797</td>\n",
       "      <td>0.536680</td>\n",
       "      <td>0.284559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.118852</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.725610</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.685315</td>\n",
       "      <td>0.377133</td>\n",
       "      <td>0.577236</td>\n",
       "      <td>0.532819</td>\n",
       "      <td>0.814066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.484211</td>\n",
       "      <td>0.756148</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.664634</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.543515</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.204633</td>\n",
       "      <td>0.280517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.310526</td>\n",
       "      <td>0.055328</td>\n",
       "      <td>0.209677</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.246875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.133959</td>\n",
       "      <td>0.650407</td>\n",
       "      <td>0.671815</td>\n",
       "      <td>0.355699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.547368</td>\n",
       "      <td>0.200820</td>\n",
       "      <td>0.747312</td>\n",
       "      <td>0.908537</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.246875</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.398601</td>\n",
       "      <td>0.496587</td>\n",
       "      <td>0.105691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.652632</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.391608</td>\n",
       "      <td>0.249147</td>\n",
       "      <td>0.504065</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.660469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.186475</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.481707</td>\n",
       "      <td>-0.038462</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.315625</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.426573</td>\n",
       "      <td>0.095563</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.362934</td>\n",
       "      <td>0.163298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.531579</td>\n",
       "      <td>0.602459</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.725610</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.419580</td>\n",
       "      <td>0.300341</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.262548</td>\n",
       "      <td>0.191593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.424180</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.228125</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.143357</td>\n",
       "      <td>0.351536</td>\n",
       "      <td>0.211382</td>\n",
       "      <td>0.034749</td>\n",
       "      <td>0.203719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.036885</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.473077</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.356643</td>\n",
       "      <td>0.153584</td>\n",
       "      <td>0.504065</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.126112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.721053</td>\n",
       "      <td>0.200820</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.396341</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.440559</td>\n",
       "      <td>0.428328</td>\n",
       "      <td>0.528455</td>\n",
       "      <td>0.617761</td>\n",
       "      <td>0.886823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       알코올_도수    사과산_함량      재_함량   재의_알칼리도   마그네슘_함량   총_페놀_함량  플라보노이드_함량  \\\n",
       "40   0.331579  0.461066  0.456989  0.451220  0.051282  0.615385   0.781250   \n",
       "96   0.273684  0.254098  0.435484  0.634146  0.012821  0.519231   0.675000   \n",
       "82   0.834211  0.172131  0.586022  0.280488  0.358974  0.776923   0.906250   \n",
       "71   0.578947  0.487705  0.494624  0.481707  0.179487  0.211538   0.106250   \n",
       "78   0.650000  0.450820  0.677419  0.817073  0.500000  0.057692   0.337500   \n",
       "90   0.839474  0.159836  0.505376  0.347561  0.435897  0.750000   0.784375   \n",
       "68   0.276316  0.096311  0.612903  0.725610  0.000000  0.503846   0.562500   \n",
       "19   0.113158  0.577869  0.247312  0.542683  0.294872  0.742308   0.653125   \n",
       "42   0.352632  0.059426  0.645161  0.457317  0.179487  0.450000   0.675000   \n",
       "35   0.244737  0.034836  0.505376  0.634146  0.217949  0.819231   0.515625   \n",
       "66   0.365789  0.141393  0.446237  0.725610  0.307692  0.288462   0.500000   \n",
       "93   0.665789  0.165984  0.591398  0.603659  0.410256  0.657692   0.715625   \n",
       "34   0.352632  0.051230  0.301075  0.548780 -0.076923  0.330769   0.471875   \n",
       "63   0.331579  0.141393  0.456989  0.597561  0.243590 -0.057692   0.165625   \n",
       "8    0.321053  0.165984  0.408602  0.512195 -0.051282  0.153846   0.481250   \n",
       "97   0.750000  0.844262  0.467742  0.573171 -0.051282 -0.103846  -0.046875   \n",
       "101  0.368421  0.125000  0.500000  0.664634  0.025641  0.573077   0.831250   \n",
       "14   0.697368  0.186475  0.537634  0.402439  0.256410  0.450000   0.687500   \n",
       "55   0.765789  0.165984  0.489247  0.414634  0.307692  0.626923   0.953125   \n",
       "3    0.744737  0.120902  0.704301  0.878049  0.025641  0.653846   0.740625   \n",
       "92   0.823684  0.325820  0.602151  0.573171  0.089744  0.165385   0.065625   \n",
       "30   0.531579  0.174180  0.397849  0.390244  0.294872  0.673077   0.784375   \n",
       "81   0.439474  0.538934  0.537634  0.664634  0.282051  0.173077   0.221875   \n",
       "64   0.884211  0.194672  0.586022  0.243902  0.153846  0.480769   0.634375   \n",
       "15   0.623684  0.612705  0.602151  0.756098  0.230769  0.211538   0.081250   \n",
       "52   0.626316  0.598361  0.408602  0.500000  0.076923  0.461538   0.684375   \n",
       "58   0.813158  0.114754  0.516129  0.378049  0.141026  0.365385   0.606250   \n",
       "11   0.592105  0.147541  0.795699  0.298780  0.333333  0.519231   0.684375   \n",
       "38   0.594737  0.215164  0.709677  0.378049  0.230769  0.673077   0.856250   \n",
       "65   0.613158  0.336066  0.532258  0.573171  0.064103  0.057692   0.003125   \n",
       "87   0.500000  0.387295  0.720430  0.634146  0.153846  0.111538   0.003125   \n",
       "31   0.471053  0.502049  0.505376  0.542683  0.051282  0.088462   0.053125   \n",
       "21   0.276316  0.043033  0.618280  0.817073 -0.076923  0.288462   0.340625   \n",
       "5    0.710526  0.118852  0.720430  0.725610  0.217949  0.673077   0.862500   \n",
       "59   0.484211  0.756148  0.602151  0.664634  0.025641  0.173077   0.050000   \n",
       "12   0.310526  0.055328  0.209677  0.378049  0.858974  0.230769   0.246875   \n",
       "69   0.547368  0.200820  0.747312  0.908537  0.410256  0.365385   0.246875   \n",
       "103  0.652632  0.180328  0.693548  0.512195  0.333333  0.423077   0.637500   \n",
       "95   0.276316  0.186475  0.516129  0.481707 -0.038462  0.134615   0.315625   \n",
       "100  0.531579  0.602459  0.516129  0.725610  0.012821  0.153846   0.343750   \n",
       "61   0.486842  0.424180  0.559140  0.573171  0.256410  0.019231   0.228125   \n",
       "44   0.100000 -0.036885  0.612903  0.634146  0.051282  0.473077   0.475000   \n",
       "57   0.721053  0.200820  0.709677  0.396341  0.397436  0.673077   0.718750   \n",
       "\n",
       "     비플라보노이드_페놀_함량  프로안토시아닌_함량      색_강도        색조  희석_와인의_투과율_OD280_OD315  \\\n",
       "40        0.632653    0.835664  0.087031  0.764228                0.579151   \n",
       "96        0.469388    0.325175  0.126280  0.308943                0.752896   \n",
       "82        0.408163    0.541958  0.466724  0.463415                0.586873   \n",
       "71        0.959184    0.506993  0.788396  0.065041                0.069498   \n",
       "78        0.163265    0.290210  0.624573  0.089431               -0.011583   \n",
       "90        0.244898    0.562937  0.435154  0.373984                0.764479   \n",
       "68        0.591837    0.216783  0.138225  0.365854                0.718147   \n",
       "19        0.204082    1.104895  0.138225  0.219512                0.571429   \n",
       "42        0.469388    0.580420  0.283276  0.577236                0.374517   \n",
       "35       -0.020408    0.430070  0.164676  0.414634                0.694981   \n",
       "66        0.408163    0.416084  0.066553  0.471545                0.629344   \n",
       "93        0.122449    0.709790  0.424061  0.406504                0.656371   \n",
       "34        0.265306    0.216783  0.290102  0.520325                0.830116   \n",
       "63        0.469388    0.363636  0.151024  0.346341                0.189189   \n",
       "8         0.469388    0.423077  0.180887  0.422764                0.710425   \n",
       "97        0.530612    0.090909  0.308874  0.081301                0.000000   \n",
       "101       0.510204    0.472028  0.226962  0.170732                0.583012   \n",
       "14        0.571429    0.541958  0.218430  0.609756                0.594595   \n",
       "55        0.367347    0.580420  0.650171  0.520325                0.683398   \n",
       "3         0.142857    0.506993  0.179181  0.715447                0.706564   \n",
       "92        0.612245    0.286713  0.718430  0.113821                0.146718   \n",
       "30        0.285714    0.562937  0.320819  0.325203                0.779923   \n",
       "81        0.061224    0.146853  0.317406  0.243902               -0.015444   \n",
       "64        0.326531    0.545455  0.338737  0.439024                0.868726   \n",
       "15        0.591837    0.346154  0.513652  0.178862                0.088803   \n",
       "52        0.265306    0.370629  0.255973  0.349593                0.644788   \n",
       "58        0.244898    0.402098  0.317406  0.560976                0.575290   \n",
       "11        0.408163    0.328671  0.283276  0.495935                0.559846   \n",
       "38        0.346939    0.433566  0.402730  0.479675                0.583012   \n",
       "65        0.469388    0.076923  0.368601  0.178862                0.440154   \n",
       "87        0.795918    0.115385  0.283276  0.235772                0.378378   \n",
       "31        0.530612    0.192308  0.766212  0.195122                0.162162   \n",
       "21        0.530612    0.342657  0.078498  0.674797                0.536680   \n",
       "5         0.306122    0.685315  0.377133  0.577236                0.532819   \n",
       "59        0.673469    0.153846  0.543515  0.048780                0.204633   \n",
       "12        0.000000    0.727273  0.133959  0.650407                0.671815   \n",
       "69        0.244898    0.398601  0.496587  0.105691                0.000000   \n",
       "103       0.306122    0.391608  0.249147  0.504065                0.594595   \n",
       "95        0.775510    0.426573  0.095563  0.487805                0.362934   \n",
       "100       0.959184    0.419580  0.300341  0.292683                0.262548   \n",
       "61        0.204082    0.143357  0.351536  0.211382                0.034749   \n",
       "44        0.571429    0.356643  0.153584  0.504065                0.378378   \n",
       "57        0.510204    0.440559  0.428328  0.528455                0.617761   \n",
       "\n",
       "       프롤린_함량  \n",
       "40   0.103476  \n",
       "96   0.080841  \n",
       "82   0.947454  \n",
       "71   0.320938  \n",
       "78   0.179466  \n",
       "90   0.559418  \n",
       "68   0.086500  \n",
       "19   0.229588  \n",
       "42   0.323363  \n",
       "35   0.491512  \n",
       "66   0.054163  \n",
       "93   0.680679  \n",
       "34   0.187551  \n",
       "63   0.478577  \n",
       "8    0.187551  \n",
       "97   0.110752  \n",
       "101  0.059822  \n",
       "14   0.575586  \n",
       "55   0.793856  \n",
       "3    0.106710  \n",
       "92   0.308812  \n",
       "30   0.490703  \n",
       "81   0.260307  \n",
       "64   0.818108  \n",
       "15   0.381568  \n",
       "52   0.611964  \n",
       "58   0.810024  \n",
       "11   0.486661  \n",
       "38   0.801940  \n",
       "65   0.405821  \n",
       "87   0.260307  \n",
       "31   0.329022  \n",
       "21   0.284559  \n",
       "5    0.814066  \n",
       "59   0.280517  \n",
       "12   0.355699  \n",
       "69   0.118836  \n",
       "103  0.660469  \n",
       "95   0.163298  \n",
       "100  0.191593  \n",
       "61   0.203719  \n",
       "44   0.126112  \n",
       "57   0.886823  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mms_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ae1948e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,075</span> (12.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,075\u001b[0m (12.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,075</span> (12.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,075\u001b[0m (12.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(mms_X_test.shape[1], )))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99d8fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cc24d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747295158.915182  103453 service.cc:152] XLA service 0x7f4c38005170 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1747295158.915238  103453 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce MX450, Compute Capability 7.5\n",
      "2025-05-15 16:45:58.936870: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1747295159.086203  103453 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3s/step - accuracy: 0.2188 - loss: 1.1369"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747295161.039351  103453 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.2422 - loss: 1.1303 - val_accuracy: 0.2791 - val_loss: 1.1098\n",
      "Epoch 2/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.3158 - loss: 1.1004 - val_accuracy: 0.4884 - val_loss: 1.0859\n",
      "Epoch 3/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.4524 - loss: 1.0728 - val_accuracy: 0.5581 - val_loss: 1.0631\n",
      "Epoch 4/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.5895 - loss: 1.0562 - val_accuracy: 0.6279 - val_loss: 1.0413\n",
      "Epoch 5/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.6635 - loss: 1.0355 - val_accuracy: 0.6744 - val_loss: 1.0207\n",
      "Epoch 6/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7684 - loss: 1.0072 - val_accuracy: 0.7442 - val_loss: 1.0007\n",
      "Epoch 7/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7791 - loss: 0.9847 - val_accuracy: 0.7674 - val_loss: 0.9803\n",
      "Epoch 8/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8209 - loss: 0.9613 - val_accuracy: 0.7907 - val_loss: 0.9605\n",
      "Epoch 9/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8108 - loss: 0.9505 - val_accuracy: 0.7907 - val_loss: 0.9415\n",
      "Epoch 10/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.8525 - loss: 0.9211 - val_accuracy: 0.7674 - val_loss: 0.9229\n",
      "Epoch 11/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.8421 - loss: 0.9079 - val_accuracy: 0.7674 - val_loss: 0.9039\n",
      "Epoch 12/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.8421 - loss: 0.8840 - val_accuracy: 0.8140 - val_loss: 0.8842\n",
      "Epoch 13/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8631 - loss: 0.8665 - val_accuracy: 0.8372 - val_loss: 0.8638\n",
      "Epoch 14/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.8527 - loss: 0.8463 - val_accuracy: 0.8372 - val_loss: 0.8428\n",
      "Epoch 15/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.8423 - loss: 0.8272 - val_accuracy: 0.8837 - val_loss: 0.8214\n",
      "Epoch 16/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.9051 - loss: 0.7980 - val_accuracy: 0.8605 - val_loss: 0.7998\n",
      "Epoch 17/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.8738 - loss: 0.7833 - val_accuracy: 0.8605 - val_loss: 0.7783\n",
      "Epoch 18/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.9367 - loss: 0.7455 - val_accuracy: 0.8605 - val_loss: 0.7573\n",
      "Epoch 19/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9054 - loss: 0.7382 - val_accuracy: 0.8605 - val_loss: 0.7360\n",
      "Epoch 20/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.9368 - loss: 0.7120 - val_accuracy: 0.8837 - val_loss: 0.7146\n",
      "Epoch 21/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9473 - loss: 0.6888 - val_accuracy: 0.9070 - val_loss: 0.6930\n",
      "Epoch 22/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.9368 - loss: 0.6598 - val_accuracy: 0.9070 - val_loss: 0.6716\n",
      "Epoch 23/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.9577 - loss: 0.6382 - val_accuracy: 0.9070 - val_loss: 0.6506\n",
      "Epoch 24/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9578 - loss: 0.6234 - val_accuracy: 0.9070 - val_loss: 0.6294\n",
      "Epoch 25/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9474 - loss: 0.5954 - val_accuracy: 0.9070 - val_loss: 0.6083\n",
      "Epoch 26/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9368 - loss: 0.5758 - val_accuracy: 0.9070 - val_loss: 0.5874\n",
      "Epoch 27/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9368 - loss: 0.5618 - val_accuracy: 0.9302 - val_loss: 0.5664\n",
      "Epoch 28/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9578 - loss: 0.5474 - val_accuracy: 0.9302 - val_loss: 0.5459\n",
      "Epoch 29/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9474 - loss: 0.5108 - val_accuracy: 0.9302 - val_loss: 0.5262\n",
      "Epoch 30/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9474 - loss: 0.4927 - val_accuracy: 0.9302 - val_loss: 0.5068\n",
      "Epoch 31/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9474 - loss: 0.4894 - val_accuracy: 0.9535 - val_loss: 0.4880\n",
      "Epoch 32/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9370 - loss: 0.4737 - val_accuracy: 0.9535 - val_loss: 0.4701\n",
      "Epoch 33/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9684 - loss: 0.4490 - val_accuracy: 0.9767 - val_loss: 0.4533\n",
      "Epoch 34/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9684 - loss: 0.4327 - val_accuracy: 0.9767 - val_loss: 0.4374\n",
      "Epoch 35/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9684 - loss: 0.4179 - val_accuracy: 0.9767 - val_loss: 0.4214\n",
      "Epoch 36/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9580 - loss: 0.4012 - val_accuracy: 0.9767 - val_loss: 0.4061\n",
      "Epoch 37/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.9580 - loss: 0.4004 - val_accuracy: 0.9767 - val_loss: 0.3906\n",
      "Epoch 38/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.9684 - loss: 0.3691 - val_accuracy: 0.9767 - val_loss: 0.3757\n",
      "Epoch 39/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.9684 - loss: 0.3516 - val_accuracy: 0.9767 - val_loss: 0.3611\n",
      "Epoch 40/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.9580 - loss: 0.3515 - val_accuracy: 0.9767 - val_loss: 0.3469\n",
      "Epoch 41/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.9788 - loss: 0.3092 - val_accuracy: 0.9767 - val_loss: 0.3335\n",
      "Epoch 42/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9580 - loss: 0.3163 - val_accuracy: 0.9767 - val_loss: 0.3204\n",
      "Epoch 43/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.9684 - loss: 0.2867 - val_accuracy: 0.9767 - val_loss: 0.3081\n",
      "Epoch 44/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.9684 - loss: 0.2837 - val_accuracy: 0.9767 - val_loss: 0.2960\n",
      "Epoch 45/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9684 - loss: 0.2730 - val_accuracy: 0.9767 - val_loss: 0.2845\n",
      "Epoch 46/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9684 - loss: 0.2706 - val_accuracy: 0.9767 - val_loss: 0.2738\n",
      "Epoch 47/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9684 - loss: 0.2562 - val_accuracy: 0.9767 - val_loss: 0.2634\n",
      "Epoch 48/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9580 - loss: 0.2538 - val_accuracy: 0.9767 - val_loss: 0.2543\n",
      "Epoch 49/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9788 - loss: 0.2177 - val_accuracy: 0.9767 - val_loss: 0.2462\n",
      "Epoch 50/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9684 - loss: 0.2286 - val_accuracy: 0.9767 - val_loss: 0.2391\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9788 - loss: 0.2067 - val_accuracy: 0.9767 - val_loss: 0.2313\n",
      "Epoch 52/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9684 - loss: 0.2027 - val_accuracy: 0.9767 - val_loss: 0.2227\n",
      "Epoch 53/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9790 - loss: 0.2032 - val_accuracy: 0.9767 - val_loss: 0.2157\n",
      "Epoch 54/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.9790 - loss: 0.2044 - val_accuracy: 0.9767 - val_loss: 0.2082\n",
      "Epoch 55/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9790 - loss: 0.1903 - val_accuracy: 0.9767 - val_loss: 0.2017\n",
      "Epoch 56/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9790 - loss: 0.1790 - val_accuracy: 0.9767 - val_loss: 0.1956\n",
      "Epoch 57/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9790 - loss: 0.1706 - val_accuracy: 0.9767 - val_loss: 0.1900\n",
      "Epoch 58/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9894 - loss: 0.1599 - val_accuracy: 0.9767 - val_loss: 0.1845\n",
      "Epoch 59/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9894 - loss: 0.1542 - val_accuracy: 0.9767 - val_loss: 0.1797\n",
      "Epoch 60/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9894 - loss: 0.1578 - val_accuracy: 0.9767 - val_loss: 0.1750\n",
      "Epoch 61/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9894 - loss: 0.1451 - val_accuracy: 0.9767 - val_loss: 0.1711\n",
      "Epoch 62/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.9790 - loss: 0.1478 - val_accuracy: 0.9767 - val_loss: 0.1679\n",
      "Epoch 63/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.9894 - loss: 0.1487 - val_accuracy: 0.9767 - val_loss: 0.1642\n",
      "Epoch 64/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.9894 - loss: 0.1356 - val_accuracy: 0.9767 - val_loss: 0.1600\n",
      "Epoch 65/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.9790 - loss: 0.1320 - val_accuracy: 0.9767 - val_loss: 0.1568\n",
      "Epoch 66/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.9790 - loss: 0.1358 - val_accuracy: 0.9767 - val_loss: 0.1539\n",
      "Epoch 67/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.9790 - loss: 0.1285 - val_accuracy: 0.9767 - val_loss: 0.1502\n",
      "Epoch 68/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9894 - loss: 0.1157 - val_accuracy: 0.9767 - val_loss: 0.1458\n",
      "Epoch 69/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9790 - loss: 0.1175 - val_accuracy: 0.9767 - val_loss: 0.1432\n",
      "Epoch 70/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9894 - loss: 0.1032 - val_accuracy: 0.9767 - val_loss: 0.1398\n",
      "Epoch 71/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9894 - loss: 0.1074 - val_accuracy: 0.9767 - val_loss: 0.1368\n",
      "Epoch 72/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9894 - loss: 0.1083 - val_accuracy: 0.9767 - val_loss: 0.1338\n",
      "Epoch 73/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9790 - loss: 0.1130 - val_accuracy: 0.9767 - val_loss: 0.1323\n",
      "Epoch 74/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9894 - loss: 0.0971 - val_accuracy: 0.9767 - val_loss: 0.1303\n",
      "Epoch 75/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9790 - loss: 0.1012 - val_accuracy: 0.9767 - val_loss: 0.1297\n",
      "Epoch 76/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9894 - loss: 0.0895 - val_accuracy: 0.9767 - val_loss: 0.1277\n",
      "Epoch 77/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9790 - loss: 0.0971 - val_accuracy: 0.9767 - val_loss: 0.1275\n",
      "Epoch 78/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9894 - loss: 0.0883 - val_accuracy: 0.9767 - val_loss: 0.1247\n",
      "Epoch 79/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.9894 - loss: 0.0742 - val_accuracy: 0.9767 - val_loss: 0.1228\n",
      "Epoch 80/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9894 - loss: 0.0815 - val_accuracy: 0.9767 - val_loss: 0.1213\n",
      "Epoch 81/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9790 - loss: 0.0820 - val_accuracy: 0.9767 - val_loss: 0.1199\n",
      "Epoch 82/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 0.0638 - val_accuracy: 0.9767 - val_loss: 0.1179\n",
      "Epoch 83/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 0.0750 - val_accuracy: 0.9767 - val_loss: 0.1166\n",
      "Epoch 84/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 0.0794 - val_accuracy: 0.9767 - val_loss: 0.1145\n",
      "Epoch 85/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 0.0683 - val_accuracy: 0.9767 - val_loss: 0.1118\n",
      "Epoch 86/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.0673 - val_accuracy: 0.9767 - val_loss: 0.1105\n",
      "Epoch 87/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 1.0000 - loss: 0.0796 - val_accuracy: 0.9767 - val_loss: 0.1099\n",
      "Epoch 88/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0610 - val_accuracy: 0.9767 - val_loss: 0.1093\n",
      "Epoch 89/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0596 - val_accuracy: 0.9767 - val_loss: 0.1082\n",
      "Epoch 90/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0564 - val_accuracy: 0.9767 - val_loss: 0.1062\n",
      "Epoch 91/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0551 - val_accuracy: 0.9767 - val_loss: 0.1051\n",
      "Epoch 92/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0625 - val_accuracy: 0.9767 - val_loss: 0.1047\n",
      "Epoch 93/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0596 - val_accuracy: 0.9767 - val_loss: 0.1033\n",
      "Epoch 94/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0662 - val_accuracy: 0.9767 - val_loss: 0.1018\n",
      "Epoch 95/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0531 - val_accuracy: 0.9767 - val_loss: 0.1009\n",
      "Epoch 96/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9767 - val_loss: 0.0990\n",
      "Epoch 97/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0428 - val_accuracy: 0.9767 - val_loss: 0.0974\n",
      "Epoch 98/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 1.0000 - loss: 0.0545 - val_accuracy: 0.9767 - val_loss: 0.0965\n",
      "Epoch 99/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 0.0440 - val_accuracy: 0.9767 - val_loss: 0.0966\n",
      "Epoch 100/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0419 - val_accuracy: 0.9767 - val_loss: 0.0962\n",
      "Epoch 101/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0421 - val_accuracy: 0.9767 - val_loss: 0.0959\n",
      "Epoch 102/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0436 - val_accuracy: 0.9767 - val_loss: 0.0945\n",
      "Epoch 103/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0470 - val_accuracy: 0.9767 - val_loss: 0.0936\n",
      "Epoch 104/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0445 - val_accuracy: 0.9767 - val_loss: 0.0932\n",
      "Epoch 105/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0417 - val_accuracy: 0.9767 - val_loss: 0.0926\n",
      "Epoch 106/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0437 - val_accuracy: 0.9767 - val_loss: 0.0924\n",
      "Epoch 107/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0408 - val_accuracy: 0.9767 - val_loss: 0.0908\n",
      "Epoch 108/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0411 - val_accuracy: 0.9767 - val_loss: 0.0906\n",
      "Epoch 109/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0408 - val_accuracy: 0.9767 - val_loss: 0.0894\n",
      "Epoch 110/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 1.0000 - loss: 0.0415 - val_accuracy: 0.9767 - val_loss: 0.0889\n",
      "Epoch 111/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0387 - val_accuracy: 0.9767 - val_loss: 0.0875\n",
      "Epoch 112/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 0.0335 - val_accuracy: 0.9767 - val_loss: 0.0869\n",
      "Epoch 113/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 0.0345 - val_accuracy: 0.9767 - val_loss: 0.0855\n",
      "Epoch 114/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.0342 - val_accuracy: 0.9767 - val_loss: 0.0853\n",
      "Epoch 115/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0359 - val_accuracy: 0.9767 - val_loss: 0.0870\n",
      "Epoch 116/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0274 - val_accuracy: 0.9767 - val_loss: 0.0873\n",
      "Epoch 117/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0296 - val_accuracy: 0.9767 - val_loss: 0.0865\n",
      "Epoch 118/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.0322 - val_accuracy: 0.9767 - val_loss: 0.0860\n",
      "Epoch 119/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0307 - val_accuracy: 0.9767 - val_loss: 0.0850\n",
      "Epoch 120/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0299 - val_accuracy: 0.9767 - val_loss: 0.0837\n",
      "Epoch 121/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 0.9767 - val_loss: 0.0824\n",
      "Epoch 122/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0290 - val_accuracy: 0.9767 - val_loss: 0.0820\n",
      "Epoch 123/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 0.9767 - val_loss: 0.0812\n",
      "Epoch 124/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0280 - val_accuracy: 0.9767 - val_loss: 0.0810\n",
      "Epoch 125/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0255 - val_accuracy: 0.9767 - val_loss: 0.0794\n",
      "Epoch 126/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0234 - val_accuracy: 0.9767 - val_loss: 0.0794\n",
      "Epoch 127/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0241 - val_accuracy: 0.9767 - val_loss: 0.0793\n",
      "Epoch 128/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0256 - val_accuracy: 0.9767 - val_loss: 0.0808\n",
      "Epoch 129/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0218 - val_accuracy: 0.9767 - val_loss: 0.0806\n",
      "Epoch 130/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0241 - val_accuracy: 0.9767 - val_loss: 0.0801\n",
      "Epoch 131/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0246 - val_accuracy: 0.9767 - val_loss: 0.0790\n",
      "Epoch 132/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0222 - val_accuracy: 0.9767 - val_loss: 0.0795\n",
      "Epoch 133/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 0.9767 - val_loss: 0.0792\n",
      "Epoch 134/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 0.9767 - val_loss: 0.0796\n",
      "Epoch 135/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0222 - val_accuracy: 0.9767 - val_loss: 0.0787\n",
      "Epoch 136/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0208 - val_accuracy: 0.9767 - val_loss: 0.0766\n",
      "Epoch 137/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0207 - val_accuracy: 0.9767 - val_loss: 0.0754\n",
      "Epoch 138/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.9767 - val_loss: 0.0748\n",
      "Epoch 139/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 0.9767 - val_loss: 0.0759\n",
      "Epoch 140/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.0193 - val_accuracy: 0.9767 - val_loss: 0.0773\n",
      "Epoch 141/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0176 - val_accuracy: 0.9767 - val_loss: 0.0770\n",
      "Epoch 142/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0177 - val_accuracy: 0.9767 - val_loss: 0.0762\n",
      "Epoch 143/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 0.9767 - val_loss: 0.0764\n",
      "Epoch 144/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 0.9767 - val_loss: 0.0756\n",
      "Epoch 145/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 0.9767 - val_loss: 0.0751\n",
      "Epoch 146/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 0.9767 - val_loss: 0.0746\n",
      "Epoch 147/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.9767 - val_loss: 0.0747\n",
      "Epoch 148/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 0.9767 - val_loss: 0.0739\n",
      "Epoch 149/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 0.9767 - val_loss: 0.0741\n",
      "Epoch 150/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 0.9767 - val_loss: 0.0737\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 0.9767 - val_loss: 0.0737\n",
      "Epoch 152/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.9767 - val_loss: 0.0731\n",
      "Epoch 153/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 0.9767 - val_loss: 0.0732\n",
      "Epoch 154/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 0.9767 - val_loss: 0.0727\n",
      "Epoch 155/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.9767 - val_loss: 0.0733\n",
      "Epoch 156/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0154 - val_accuracy: 0.9767 - val_loss: 0.0729\n",
      "Epoch 157/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.9767 - val_loss: 0.0721\n",
      "Epoch 158/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.9767 - val_loss: 0.0718\n",
      "Epoch 159/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.9767 - val_loss: 0.0721\n",
      "Epoch 160/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.9767 - val_loss: 0.0720\n",
      "Epoch 161/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.9767 - val_loss: 0.0718\n",
      "Epoch 162/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 0.9767 - val_loss: 0.0715\n",
      "Epoch 163/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.9767 - val_loss: 0.0713\n",
      "Epoch 164/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.9767 - val_loss: 0.0720\n",
      "Epoch 165/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9767 - val_loss: 0.0720\n",
      "Epoch 166/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.9767 - val_loss: 0.0714\n",
      "Epoch 167/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.9767 - val_loss: 0.0717\n",
      "Epoch 168/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.9767 - val_loss: 0.0713\n",
      "Epoch 169/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 0.9767 - val_loss: 0.0709\n",
      "Epoch 170/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.9767 - val_loss: 0.0708\n",
      "Epoch 171/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.9767 - val_loss: 0.0712\n",
      "Epoch 172/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.9767 - val_loss: 0.0706\n",
      "Epoch 173/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.9767 - val_loss: 0.0707\n",
      "Epoch 174/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.9767 - val_loss: 0.0704\n",
      "Epoch 175/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.9767 - val_loss: 0.0705\n",
      "Epoch 176/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.9767 - val_loss: 0.0699\n",
      "Epoch 177/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9767 - val_loss: 0.0695\n",
      "Epoch 178/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9767 - val_loss: 0.0699\n",
      "Epoch 179/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9767 - val_loss: 0.0694\n",
      "Epoch 180/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9767 - val_loss: 0.0700\n",
      "Epoch 181/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9767 - val_loss: 0.0691\n",
      "Epoch 182/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9767 - val_loss: 0.0696\n",
      "Epoch 183/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.9767 - val_loss: 0.0690\n",
      "Epoch 184/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9767 - val_loss: 0.0694\n",
      "Epoch 185/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.9767 - val_loss: 0.0692\n",
      "Epoch 186/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.9767 - val_loss: 0.0692\n",
      "Epoch 187/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.9767 - val_loss: 0.0694\n",
      "Epoch 188/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.9767 - val_loss: 0.0692\n",
      "Epoch 189/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9767 - val_loss: 0.0691\n",
      "Epoch 190/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.9767 - val_loss: 0.0692\n",
      "Epoch 191/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.9767 - val_loss: 0.0694\n",
      "Epoch 192/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.9767 - val_loss: 0.0689\n",
      "Epoch 193/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9767 - val_loss: 0.0688\n",
      "Epoch 194/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.9767 - val_loss: 0.0681\n",
      "Epoch 195/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9767 - val_loss: 0.0679\n",
      "Epoch 196/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9767 - val_loss: 0.0683\n",
      "Epoch 197/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9767 - val_loss: 0.0686\n",
      "Epoch 198/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9767 - val_loss: 0.0688\n",
      "Epoch 199/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9767 - val_loss: 0.0681\n",
      "Epoch 200/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 201/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.9767 - val_loss: 0.0682\n",
      "Epoch 202/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9767 - val_loss: 0.0689\n",
      "Epoch 203/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.9767 - val_loss: 0.0688\n",
      "Epoch 204/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.9767 - val_loss: 0.0686\n",
      "Epoch 205/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9767 - val_loss: 0.0687\n",
      "Epoch 206/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9767 - val_loss: 0.0683\n",
      "Epoch 207/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9767 - val_loss: 0.0677\n",
      "Epoch 208/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9767 - val_loss: 0.0677\n",
      "Epoch 209/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9767 - val_loss: 0.0681\n",
      "Epoch 210/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9767 - val_loss: 0.0678\n",
      "Epoch 211/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9767 - val_loss: 0.0679\n",
      "Epoch 212/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9767 - val_loss: 0.0677\n",
      "Epoch 213/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9767 - val_loss: 0.0677\n",
      "Epoch 214/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9767 - val_loss: 0.0675\n",
      "Epoch 215/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9767 - val_loss: 0.0677\n",
      "Epoch 216/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9767 - val_loss: 0.0677\n",
      "Epoch 217/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9767 - val_loss: 0.0675\n",
      "Epoch 218/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 219/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 220/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9767 - val_loss: 0.0672\n",
      "Epoch 221/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 222/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9767 - val_loss: 0.0679\n",
      "Epoch 223/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9767 - val_loss: 0.0684\n",
      "Epoch 224/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9767 - val_loss: 0.0685\n",
      "Epoch 225/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9767 - val_loss: 0.0684\n",
      "Epoch 226/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9767 - val_loss: 0.0683\n",
      "Epoch 227/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9767 - val_loss: 0.0679\n",
      "Epoch 228/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 229/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9767 - val_loss: 0.0675\n",
      "Epoch 230/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9767 - val_loss: 0.0672\n",
      "Epoch 231/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9767 - val_loss: 0.0671\n",
      "Epoch 232/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 233/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 234/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 235/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 236/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 237/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 238/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9767 - val_loss: 0.0677\n",
      "Epoch 239/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9767 - val_loss: 0.0675\n",
      "Epoch 240/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9767 - val_loss: 0.0678\n",
      "Epoch 241/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9767 - val_loss: 0.0678\n",
      "Epoch 242/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9767 - val_loss: 0.0678\n",
      "Epoch 243/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9767 - val_loss: 0.0675\n",
      "Epoch 244/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9767 - val_loss: 0.0673\n",
      "Epoch 245/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9767 - val_loss: 0.0671\n",
      "Epoch 246/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9767 - val_loss: 0.0673\n",
      "Epoch 247/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9767 - val_loss: 0.0675\n",
      "Epoch 248/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9767 - val_loss: 0.0675\n",
      "Epoch 249/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9767 - val_loss: 0.0673\n",
      "Epoch 250/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 251/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9767 - val_loss: 0.0673\n",
      "Epoch 252/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9767 - val_loss: 0.0670\n",
      "Epoch 253/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9767 - val_loss: 0.0672\n",
      "Epoch 254/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9767 - val_loss: 0.0673\n",
      "Epoch 255/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 256/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9767 - val_loss: 0.0670\n",
      "Epoch 257/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 258/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 259/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9767 - val_loss: 0.0677\n",
      "Epoch 260/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 261/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 262/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 263/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 264/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9767 - val_loss: 0.0672\n",
      "Epoch 265/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9767 - val_loss: 0.0671\n",
      "Epoch 266/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9767 - val_loss: 0.0671\n",
      "Epoch 267/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9767 - val_loss: 0.0672\n",
      "Epoch 268/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9767 - val_loss: 0.0672\n",
      "Epoch 269/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9767 - val_loss: 0.0673\n",
      "Epoch 270/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9767 - val_loss: 0.0670\n",
      "Epoch 271/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9767 - val_loss: 0.0673\n",
      "Epoch 272/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9767 - val_loss: 0.0671\n",
      "Epoch 273/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9767 - val_loss: 0.0670\n",
      "Epoch 274/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9767 - val_loss: 0.0671\n",
      "Epoch 275/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 276/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9767 - val_loss: 0.0673\n",
      "Epoch 277/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 278/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 279/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9767 - val_loss: 0.0673\n",
      "Epoch 280/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9767 - val_loss: 0.0671\n",
      "Epoch 281/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9767 - val_loss: 0.0672\n",
      "Epoch 282/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9767 - val_loss: 0.0672\n",
      "Epoch 283/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 284/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9767 - val_loss: 0.0677\n",
      "Epoch 285/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9767 - val_loss: 0.0675\n",
      "Epoch 286/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9767 - val_loss: 0.0672\n",
      "Epoch 287/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9767 - val_loss: 0.0673\n",
      "Epoch 288/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9767 - val_loss: 0.0672\n",
      "Epoch 289/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9767 - val_loss: 0.0675\n",
      "Epoch 290/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9767 - val_loss: 0.0680\n",
      "Epoch 291/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9767 - val_loss: 0.0678\n",
      "Epoch 292/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9767 - val_loss: 0.0679\n",
      "Epoch 293/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9767 - val_loss: 0.0678\n",
      "Epoch 294/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9767 - val_loss: 0.0677\n",
      "Epoch 295/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 296/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9767 - val_loss: 0.0675\n",
      "Epoch 297/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9767 - val_loss: 0.0673\n",
      "Epoch 298/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9767 - val_loss: 0.0673\n",
      "Epoch 299/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 300/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 302/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9767 - val_loss: 0.0675\n",
      "Epoch 303/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 304/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9767 - val_loss: 0.0672\n",
      "Epoch 305/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9767 - val_loss: 0.0671\n",
      "Epoch 306/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9767 - val_loss: 0.0677\n",
      "Epoch 307/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9767 - val_loss: 0.0680\n",
      "Epoch 308/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9767 - val_loss: 0.0680\n",
      "Epoch 309/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9767 - val_loss: 0.0679\n",
      "Epoch 310/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 311/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9767 - val_loss: 0.0674\n",
      "Epoch 312/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9767 - val_loss: 0.0675\n",
      "Epoch 313/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 314/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9767 - val_loss: 0.0675\n",
      "Epoch 315/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 316/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9767 - val_loss: 0.0678\n",
      "Epoch 317/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9767 - val_loss: 0.0677\n",
      "Epoch 318/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9767 - val_loss: 0.0676\n",
      "Epoch 319/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9767 - val_loss: 0.0679\n",
      "Epoch 320/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9767 - val_loss: 0.0679\n",
      "Epoch 321/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9767 - val_loss: 0.0682\n",
      "Epoch 322/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9767 - val_loss: 0.0680\n",
      "Epoch 323/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9767 - val_loss: 0.0682\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "# 콜백 설정\n",
    "early_stop = EarlyStopping(patience=50)\n",
    "\n",
    "\n",
    "# 파일 저장 포맷\n",
    "filepath = \"./model/whitewine_loss:{val_loss:04f}__{epoch:04d}.keras\"  \n",
    "\n",
    "# 체크포인트 콜백\n",
    "model_save = ModelCheckpoint(filepath=filepath, save_best_only=True)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    mms_X_train ,y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    validation_data=(mms_X_test , y_test),\n",
    "    callbacks=[early_stop, model_save]\n",
    ")\n",
    "\n",
    "# 학습 결과 시각화\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend([\"train\", \"valid\"])  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6afd9d5",
   "metadata": {},
   "source": [
    "# 머신러닝 스케일러와 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f94ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29266a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>와인_종류</th>\n",
       "      <th>알코올_도수</th>\n",
       "      <th>사과산_함량</th>\n",
       "      <th>재_함량</th>\n",
       "      <th>재의_알칼리도</th>\n",
       "      <th>마그네슘_함량</th>\n",
       "      <th>총_페놀_함량</th>\n",
       "      <th>플라보노이드_함량</th>\n",
       "      <th>비플라보노이드_페놀_함량</th>\n",
       "      <th>프로안토시아닌_함량</th>\n",
       "      <th>색_강도</th>\n",
       "      <th>색조</th>\n",
       "      <th>희석_와인의_투과율_OD280_OD315</th>\n",
       "      <th>프롤린_함량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.76</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.70</td>\n",
       "      <td>19.5</td>\n",
       "      <td>132</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.35</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12.67</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.24</td>\n",
       "      <td>18.0</td>\n",
       "      <td>99</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.46</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.16</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.58</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.36</td>\n",
       "      <td>19.1</td>\n",
       "      <td>106</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.95</td>\n",
       "      <td>6.90</td>\n",
       "      <td>1.09</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>13.86</td>\n",
       "      <td>1.51</td>\n",
       "      <td>2.67</td>\n",
       "      <td>25.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.38</td>\n",
       "      <td>1.36</td>\n",
       "      <td>3.16</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.22</td>\n",
       "      <td>25.0</td>\n",
       "      <td>124</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3.20</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "      <td>12.43</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.29</td>\n",
       "      <td>21.5</td>\n",
       "      <td>86</td>\n",
       "      <td>2.74</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.84</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3</td>\n",
       "      <td>12.20</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.32</td>\n",
       "      <td>19.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.73</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.83</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>13.51</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>19.0</td>\n",
       "      <td>110</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.54</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>12.70</td>\n",
       "      <td>3.87</td>\n",
       "      <td>2.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.19</td>\n",
       "      <td>3.13</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2</td>\n",
       "      <td>12.51</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.98</td>\n",
       "      <td>20.5</td>\n",
       "      <td>85</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.57</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     와인_종류  알코올_도수  사과산_함량  재_함량  재의_알칼리도  마그네슘_함량  총_페놀_함량  플라보노이드_함량  \\\n",
       "0        1   13.76    1.53  2.70     19.5      132     2.95       2.74   \n",
       "1        2   12.67    0.98  2.24     18.0       99     2.20       1.94   \n",
       "2        1   13.58    1.66  2.36     19.1      106     2.86       3.19   \n",
       "3        2   13.86    1.51  2.67     25.0       86     2.95       2.86   \n",
       "4        1   13.05    2.05  3.22     25.0      124     2.63       2.68   \n",
       "..     ...     ...     ...   ...      ...      ...      ...        ...   \n",
       "101      2   12.43    1.53  2.29     21.5       86     2.74       3.15   \n",
       "102      3   12.20    3.03  2.32     19.0       96     1.25       0.49   \n",
       "103      1   13.51    1.80  2.65     19.0      110     2.35       2.53   \n",
       "104      2   12.70    3.87  2.40     23.0      101     2.83       2.55   \n",
       "105      2   12.51    1.73  1.98     20.5       85     2.20       1.92   \n",
       "\n",
       "     비플라보노이드_페놀_함량  프로안토시아닌_함량  색_강도    색조  희석_와인의_투과율_OD280_OD315  프롤린_함량  \n",
       "0             0.50        1.35  5.40  1.25                    3.00    1235  \n",
       "1             0.30        1.46  2.62  1.23                    3.16     450  \n",
       "2             0.22        1.95  6.90  1.09                    2.88    1515  \n",
       "3             0.21        1.87  3.38  1.36                    3.16     410  \n",
       "4             0.47        1.92  3.58  1.13                    3.20     830  \n",
       "..             ...         ...   ...   ...                     ...     ...  \n",
       "101           0.39        1.77  3.94  0.69                    2.84     352  \n",
       "102           0.40        0.73  5.50  0.66                    1.83     510  \n",
       "103           0.29        1.54  4.20  1.10                    2.87    1095  \n",
       "104           0.43        1.95  2.57  1.19                    3.13     463  \n",
       "105           0.32        1.48  2.94  1.04                    3.57     672  \n",
       "\n",
       "[106 rows x 14 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/wine_train.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9703c91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "와인_종류\n",
       "2    42\n",
       "1    35\n",
       "3    29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['와인_종류'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5584ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e254ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('와인_종류', axis=1)\n",
    "y = data['와인_종류']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ed0f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X ,y, test_size=0.4, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6924d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "train_temp = mms.fit_transform(X_train)\n",
    "test_temp = mms.transform(X_test)\n",
    "mms_X_train = pd.DataFrame(train_temp, columns= X_train.columns, index= X_train.index)\n",
    "mms_X_test = pd.DataFrame(test_temp, columns= X_test.columns, index= X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4507a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18cc8ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/MinMax_info2.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mms, \"./model/MinMax_info2.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85801b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      0.94      0.97        17\n",
      "           3       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.98        43\n",
      "   macro avg       0.97      0.98      0.98        43\n",
      "weighted avg       0.98      0.98      0.98        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "rfc = RandomForestClassifier(max_depth=3, n_estimators=500, n_jobs=1, random_state=42)\n",
    "rfc.fit(mms_X_train, y_train)\n",
    "pred = rfc.predict(mms_X_test)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "92ba8575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/rfc_model.joblib']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rfc, \"./model/rfc_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f6822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e09558a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f98050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c332bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19404ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
